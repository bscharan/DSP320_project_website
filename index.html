<html>
	<head>
		<style type="text/css">
			
                        @import url('https://fonts.googleapis.com/css?family=Indie+Flower|Merriweather');
			body{font-family:'Merriweather', serif;}
			p{display: inline-block;}
			img{display: block;}
			.container{width: 90%;position absolute;margin: auto;}
			.title{position: relative;width: 90%;margin: auto;text-align: center;font-weight: bold;font-size: 24px;padding: 1%;}
			.section{position: relative;width: 90%;margin: auto;padding: 2%;}
			.subsection{position: relative; width: 98%;text-align: justify;padding: 15px;}
			.heading{position: relative; width: 98%;text-align: left;font-size: 20px;font-weight: bold;}
			.text{width: 95%;font-size: 14px;text-align: justify;padding: 10px 15px 10px 10px;}
			.authors{position: relative;width: 80%;margin: auto;padding: 2%;font-style: italic;text-align: center;font-size: 12px;}
			.image{width: 95%;font-size: 12px;text-align: left;}
		</style>
	</head>
	<body>
		<div class="container">
			<div class="title">Automatic Speech Sequence Segmentation </div>

			<div class="authors">

				<!-- Start edit here  -->
				<p>Bhukya Venkatesh, Roll No.: 150102012, Branch: ECE</p>; &nbsp; &nbsp;
				<p>Bodda Sai Charan, Roll No.: 150102013, Branch: ECE</p>; &nbsp; &nbsp;<br/>
				<p>Chintapalli Tarun, Roll No.: 150102014, Branch: ECE</p>; &nbsp; &nbsp;
				<p>Gaddabathini Rahul, Roll No.: 150102019, Branch: ECE</p>; &nbsp; &nbsp;
				<!-- Stop edit here -->

			</div>


			<div class="section">
				<div class="heading">Abstract</div>
				<div class="text">

					<!-- Start edit here  -->
					This project aims at an unsupervised method of speaker segmention and clustering of audio data using MFCC(Mel Frequency Cepstral Coefficients) and features extracted from the same.
					
					here the characteristics of speaker or speech and number of speakers is unknown
					speech sequences based on speaker transitions.
					Additionally, it will identify the number of speakers along with the zones where single or multiple speakers are active.
					
					
					
					The first step before doing any audio processing is extracting features from the audio data.
					Best feature that that describes the human perception of sensitivity with respect to
				    frequency of identifying different speakers are mel-frequency cepstral coefficents.
					Followed by calculation of Delta coefficients, Delta-Delta(accelaration) coefficients, Which are then fed into a clustering algorithm followed by speech and speaker segmentation.
					<!-- Stop edit here -->

				</div>
			</div>

			<div class="section">
				<div class="heading">1. Introduction</div>
				<div class="text">

					<!-- Start edit here  -->
					Nowadays, a rapid increase in the volume of recorded speech is manifested.
					Indeed, television and audio broadcasting, meeting recordings, and voice mails have become a commonplace.
					However, the huge volume size hinders content organization, navigation, browsing, and retrieval. Speaker segmentation and speaker clustering are tools that alleviate the management of huge audio archives.
					Speaker segmentation aims at splitting an audio stream into acoustically homogeneous segments
					
					With the rapid advancement in technology,
					It is very important for organisations and companies to organise speech data into different classes.
					
					
					<!-- Stop edit here -->

				</div>

				<div class="subsection">
					<div class="heading">1.1 Introduction to Problem</div>
					<div class="text">

						<!-- Start edit here  -->
					The Main Aim of this project is to segment and cluster an audio sample based on speaker when number of speakers are not known before hand.
					
					Main challenge in the process of speaker recognition is separting audio based on speaker.It can enhance the readability of an automatic
					speech transcription by structuring the audio 
					stream into speaker turns and, when used together with speaker recognition systems, by providing the speaker's true identity.Other challenges are
					due to multiple speakers present at the time instant
						<!-- Stop edit here -->

					</div>
				</div>

				<div class="subsection">
					<div class="heading">1.2 Figure</div>
					<div class="image">

						<!-- Start edit here  -->
                                                <img src="Pictures/Screenshot (81).png" alt="This text displays when the image is unavailable" width="400px" height=""/>
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">1.3 Literature Review</div>
					<div class="text">

						<!-- Start edit here  -->
						Write something here.
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">1.4 Proposed Approach</div>
					<div class="text">

						<!-- Start edit here  -->
			The technique of speaker segmentation relies on the following steps :-<br />
		    1) Removing noise from input audio sample (using Amplitude threshold,ZCR) <br />
                    2) MFCC feature extraction<br />
                    3) Delta,delta-delta and other features from MFCC <br />
                    4) Speech segmentation and Clustering using k-means clustering and spherical k-means clustering<br />
										
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">1.5 Report Organization</div>
					<div class="text">

						<!-- Start edit here  -->
						Write something here.
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

			<div class="section">
				<div class="heading">2. Proposed Approach</div>
				<div class="text">

					<!-- Start edit here  -->
					
					The technique of speaker segmentation relies on the following steps :-<br /><br />
                                        1) Removal of noise for input sound sample<br />
											Most of the noise is present in the 'silence' part of the speech signal. So, the task is to identify the silent part 
											of the speech signal and to reduce the noise present there.The silence detection from the audio signal is carried 
											out using amplitude thresholding.In this method, the audio 
											sample is broken down into many small frames each of 20ms.In each of these frames, maximum amplitude is found. If the 
											maximum amplitude of a particular frame is less than the threshold (0.05), the data of the frame is replaced by zeros.In this way,silence is detected and noise present is removed.<br />
											<br />
                                        2) MFCC feature extraction<br />
											After the removal of noise from the audio signal, features like MFCC, delta-MFCC and Delta-Delta MFCC are extracted from it. Extraction of MFC coefficents from the audio signal is carried out as follows<br />
											The speech signal is first preemphasised using a first order FIR filter The preemphasised speech signal is subjected to the short-time Fourier transform analysis with frame durations 
											of 25, frame shifts of 10 and analysis hamming window function. This is followed by magnitude 
											spectrum computation followed by filterbank design with 16 triangular 
											filters uniformly spaced on the mel scale between lower and upper 
											frequency limits as 300 Hz and 3000 Hz. The filterbank is applied to 
											the magnitude spectrum values to produce filterbank energies (FBEs) 
											.Log-compressed FBEs are then decorrelated using the 
											discrete cosine transform to produce cepstral coefficients. <br /><br />
                                        3) Delta,delta-delta and other features from MFCC <br />
											Delta and delta-delta are calculated from the MFCCs using the formulae:
											
											<br /><br /><br />
											
											Silences found in the first step are employed here, The 12 dimensional MFCCs found between two adjacent silences are taken average and stored in an other matrix 
											corresponding to the speech signal.<br /><br />
                                        4) Speech segmentation and Clustering using k-means clustering and spherical k-means clustering<br />
											Here, we assume that there is at least 5ms scilence between each speaker, 
											The mean values of the MFCCs between the adjacent silences are calculated clustered using K-means clustering and spherical K-means Clustering. The audio date corresponding to the 
											mean values of the MFCCs are joined together and hence the speech audio of different speakers are obtained seperately.<br /><br />
				
										
					<!-- Stop edit here -->

				</div>
			</div>

			<div class="section">
				<div class="heading">3. Experiments &amp; Results</div>
				<div class="subsection">
					<div class="heading">3.1 Dataset Description</div>
					<div class="text">

						<!-- Start edit here  -->
						<audio controls>
                                               <source src="Pictures/123.wav" type="audio/wav">
                                               </audio>
						
						
						<H3><b>Clustered audio according to speaker using Kmeans</b></H3>	
						
							
						<p>speaker 1 clustered audio using Kmeans</p>	
						<audio controls>
                                               <source src="Pictures/kmean1.wav" alt="speaker 1 clustered audio using Kmeans" type="audio/wav">
                                               </audio>
						<p>speaker 2 clustered audio using Kmeans</p>	
						<audio controls>
                                               <source src="Pictures/kmean2.wav" alt="speaker 2 clustered audio using Kmeans" type="audio/wav">
                                               </audio>
							
							
							
							
						<H3><b>Clustered audio according to speaker using Spherical-Kmeans</b></H3>
						
						<p>speaker 1 clustered audio using spherical- Kmeans</p>	
					       <audio controls>
						
                                               <source src="Pictures/spk1.wav" alt="speaker 1 clustered audio using spherical- Kmeans" type="audio/wav">
                                               </audio>
						<p>speaker 2 clustered audio using spherical- Kmeans</p>
						<audio controls>
                                               <source src="Pictures/spk2.wav"alt="speaker 2 clustered audio using spherical-Kmeans" type="audio/wav">
                                               </audio>	
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">3.2 Discussion</div>
					<div class="text">

						<!-- Start edit here  -->
						Write something here.
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

			<div class="section">
				<div class="heading">4. Conclusions</div>
				<div class="subsection">
					<div class="heading">4.1 Summary</div>
					<div class="text">

						<!-- Start edit here  -->
						Write something here.
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">4.2 Future Extensions</div>
					<div class="text">

						<!-- Start edit here  -->
						Write something here.
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

		</div>
	</body>
</html>
